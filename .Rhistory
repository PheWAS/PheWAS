con = odbcConnect("NZSQL")
med_non_pl <- sqlAll(con,paste0("select * from
(select ind_seq,count(*) as non_pl from clin_docs where (lower(content) like '%enbrel%' or lower(content) like '%etanercept%')
and ind_seq in (",ids,")
group by ind_seq
) a
full outer join
(select ind_seq,count(*) as pl from clin_docs_pl where (lower(content) like '%enbrel%' or lower(content) like '%etanercept%')
and ind_seq in (",ids,")
group by ind_seq
) b using (ind_seq);"))
names(med_non_pl)=tolower(names(med_non_pl))
demo= sqlAll(con,demographics)
names(demo)=tolower(names(demo))
med_info <- sqlAll(con,"select * from tnf_enbrel_review_first_enb full outer join tnf_enbrel_review_humira using (ind_seq)
full outer join tnf_enbrel_review_remicade using (ind_seq);")
source('~/Dropbox/research/tnf/r/predicting_unsure_non_pl.R')
table(outcome)
table(outcome$unsure)
table(outcome$non)
table(outcome$eff)
mod=glm(unsure ~ non_pl+pl, data=data)
head(data)
con = odbcConnect("NZSQL")
med_non_pl <- sqlAll(con,paste0("select * from
(select ind_seq,count(*) as non_pl from clin_docs where (lower(content) like '%enbrel%' or lower(content) like '%etanercept%')
and ind_seq in (",ids,")
group by ind_seq
) a
full outer join
(select ind_seq,count(*) as pl from clin_docs_pl where (lower(content) like '%enbrel%' or lower(content) like '%etanercept%')
and ind_seq in (",ids,")
group by ind_seq
) b using (ind_seq);"))
names(med_non_pl)=tolower(names(med_non_pl))
demo= sqlAll(con,demographics)
names(demo)=tolower(names(demo))
med_info <- sqlAll(con,"select * from tnf_enbrel_review_first_enb full outer join tnf_enbrel_review_humira using (ind_seq)
full outer join tnf_enbrel_review_remicade using (ind_seq);")
names(med_info)=tolower(names(med_info))
close(con)
data=merge(outcome,med_non_pl,all.x=T)
data=merge(data,med_info,all.x=T)
data[is.na(data$pl),]$pl=0
data[is.na(data$non_pl),]$non_pl=0
data[is.na(data$prescription_count),]$prescription_count=0
data$has_duration=!is.na(data$duration)
data[is.na(data$duration),]$duration=0
data$prescription_density=data$prescription_count/(data$duration+1)
data$adj_prescription_density=data$prescription_count/(data$duration/180+1)
data[is.na(data$rem_after_enb_count),]$rem_after_enb_count=0
data[is.na(data$hum_after_enb_count),]$hum_after_enb_count=0
#Just the pl counts
mod=glm(unsure ~ non_pl+pl, data=data)
summary(mod)
mod=glm(unsure ~ pl + non_pl + (non_pl>10) + prescription_count + duration + has_duration + prescription_density
+ is.na(first_hum_after_enb) + is.na(first_rem_after_enb)
+ rem_after_enb_count + hum_after_enb_count
, data=data)
summary(mod)
getStats(prediction(mod$fitted.values,mod$y))
table(mod$fitted.values,mod$y)
table(mod$fitted.values>.5,mod$y)
summary(mod$fitted.values)
table(mod$fitted.values>..2,mod$y)
table(mod$fitted.values>.2,mod$y)
table(mod$fitted.values>.4,mod$y)
table(mod$fitted.values>.3,mod$y)
table(mod$fitted.values>.2,mod$y)
table(mod$fitted.values>.2,mod$y,data$non)
table(mod$fitted.values>.3,mod$y,data$non)
table(mod$fitted.values>.3)
table(mod$fitted.values>.3,mod4y)
table(mod$fitted.values>.3,mod$y)
table(mod$fitted.values>.5,mod$y)
table(mod$fitted.values>.4,mod$y)
table(data$unsure,data$non_pl>5)
table(data$non_pl>5,data$unsure)
table(data$non_pl<5,data$unsure)
table(data$non_pl<10,data$unsure)
table(data$non_pl<5,data$unsure,data$non)
?write.table
library(randomForest)
?randomForest
library(randomForest)
?rf
randomForest
?randomForest
?glm
library(randomForest)
?randomForest
?tune
??tune
library(e1071)
library(randomForest)
?tune.randomForest
?tune.control
?tune.randomForest
?tune
?tune.contro
?tune.control
?tune
?randomForest
time()
?time
date()
library(e1071)
?tune
?tune.rf
?tune.randomForest
library(randomForest)
?randomForest
library(randomForest)
?randomForest
?save
library(boot)
boot
?boot
library(randomForest)
?randomForest
sqrt(90000)
library(boot)
boot
?index.array
boot:::index.array
boot:::ordinary.array
?anova
?t.test
?data
data()
data(iris)
head(iris)
table(iris$Species)
?reshape
d=data.frame(set=iris[iris$Species="setosa",]$Petal.Width,vers=iris[iris$Species="versicolor",]$Petal.Width,virg=iris[iris$Species="virginica",]$Petal.Width)
d=data.frame(set=iris[iris$Species=="setosa",]$Petal.Width,vers=iris[iris$Species=="versicolor",]$Petal.Width,virg=iris[iris$Species=="virginica",]$Petal.Width)
head(d)
anova(d)
?anova
?aov
aov(Species ~ Petal.Width, data=iris)
aov(Petal.Width ~ Species, data=iris)
summary(aov(Petal.Width ~ Species, data=iris))
summary(aov(Petal.Width ~ Species, data=iris))$p
names(summary(aov(Petal.Width ~ Species, data=iris)))
summary(aov(Petal.Width ~ Species, data=iris))$P
attributes(summary(aov(Petal.Width ~ Species, data=iris)))
summary(aov(Petal.Width ~ Species, data=iris))[[1]]
summary(aov(Petal.Width ~ Species, data=iris))[[1]]$p
summary(aov(Petal.Width ~ Species, data=iris))[[1]]$P
summary(aov(Petal.Width ~ Species, data=iris))[[1]]$P[1]
library(snowfall)
?sfClusterApplyLB
?list.expand
??expand
expand.grid(a=1:3,b=4:5)
options=expand.grid(group=1:groups,token=unique(pred.outcome$token))
date()
library(irr)
con=odbcConnect("vger1tnf")
kappa_reviews = sqlQuery(con,"select * from kappa_charts;")
close(con)
library(RODBC)
con=odbcConnect("vger1tnf")
kappa_reviews = sqlQuery(con,"select * from kappa_charts;")
close(con)
kappa_reviews
con=odbcConnect("vger1tnf")
kappa_reviews = sqlQuery(con,"select * from kappa_charts;")
close(con)
kappa_reviews
kappa_reviews=kappa_reviews[kappa_reviews$lid!=752034&kappa_reviews$anne=="enbrel_1a: Efficacious",]
con=odbcConnect("vger1tnf")
kappa_reviews = sqlQuery(con,"select * from kappa_charts;")
close(con)
kappa_reviews=kappa_reviews[!(kappa_reviews$lid==752034&kappa_reviews$anne=="enbrel_1a: Efficacious"),]
kappa2(kappa_reviews[,2:3])
kappa2(kappa_reviews[kappa_reviews$which=="old",2:3])
kappa2(kappa_reviews[kappa_reviews$which=="new",2:3])
kappa_reviews
kappa2(kappa_reviews[kappa_reviews$which=="old",2:3])
kappa_reviews$which=="old"
kappa2(kappa_reviews[kappa_reviews$which=="old"&kappa_reviews$anne!="X",2:3])
kappa_reviews[kappa_reviews$which=="old"&kappa_reviews$anne!="X",2:3]
kappa2(kappa_reviews[kappa_reviews$which=="new",2:3])
setwd("~/tnf/apply/")
library(RODBC)
sqlAll = function(con, query) {
data = sqlQuery(con, query,rows_at_time=1024)
new = sqlFetchMore(con)
while((!is.null(dim(new)))&&(dim(new)[1]!=0)) {
data=rbind(data,new)
new=sqlFetchMore(con)
}
return(data)
}
library("ROCR")
library(RWeka)
library(Snowball)
library(gsubfn)
library(snowfall)
library(dplyr)
?by
??lower
??tolower
??lowercase
??to.lower
??lower
?paste0
library(dplyr)
install.package(dplyr)
install.packages(c("dplyr","RODBC","ROCR","e1071","randomForest"))
install.package(dev.tools)
install.packages("dev.tools")
install.packages("devtools")
library(devtools)
install_github("PheWAS/PheWAS")
load("~/tnf/ready_to_go28oct14.RData")
train.data=merge(outcome.complete[outcome.complete$un==F,c("lid","lbool")], data, by="lid")
test.outcome=outcome.complete[outcome.complete$unsure==1,]
test.outcome[test.outcome$eff==1,]$lbool="eff"
test.outcome[test.outcome$non==1,]$lbool="non"
test.outcome=test.outcome[,c("lid","lbool")]
test.data=merge(test.outcome,data,by="lid")
train.data$lbool=as.factor(train.data$lbool)
ignore=-1:-2
mod<-randomForest(x=train.data[,ignore],y=train.data$lbool)
pred=predict(mod,test.data[,ignore],type="prob")
library(ggplot2)
test.out=data.frame(p.non=pred[,"non"],lbool=test.data$lbool,un=T)
train.out=data.frame(p.non=mod$votes[,"non"],lbool=mod$y,un=F)
train.out$lbool=ifelse(train.out$lbool=="eff","Efficacious","Non-Efficacious")
library(randomForest)
ignore=-1:-2
mod<-randomForest(x=train.data[,ignore],y=train.data$lbool)
pred=predict(mod,test.data[,ignore],type="prob")
library(ggplot2)
test.out=data.frame(p.non=pred[,"non"],lbool=test.data$lbool,un=T)
train.out=data.frame(p.non=mod$votes[,"non"],lbool=mod$y,un=F)
train.out$lbool=ifelse(train.out$lbool=="eff","Efficacious","Non-Efficacious")
install.packages("randomForest")
library(randomForest)
ignore=-1:-2
mod<-randomForest(x=train.data[,ignore],y=train.data$lbool)
pred=predict(mod,test.data[,ignore],type="prob")
library(ggplot2)
test.out=data.frame(p.non=pred[,"non"],lbool=test.data$lbool,un=T)
train.out=data.frame(p.non=mod$votes[,"non"],lbool=mod$y,un=F)
train.out$lbool=ifelse(train.out$lbool=="eff","Efficacious","Non-Efficacious")
h.plot=qplot(p.non,data=both.out, geom="histogram") + ggtitle("Distribution of Tree Votes by Class") +
facet_grid( lbool ~ .,margins=F) + xlab("Probability of Non-Efficacious") +
aes(y= ..density..)
h.plot
both.out=rbind(train.out,data.frame(p.non=pred[,"non"],lbool="Unsure",un=T))
h.plot=qplot(p.non,data=both.out, geom="histogram") + ggtitle("Distribution of Tree Votes by Class") +
facet_grid( lbool ~ .,margins=F) + xlab("Probability of Non-Efficacious") +
aes(y= ..density..)
h.plot
h.plot=qplot(p.non,data=both.out, geom="histogram") + ggtitle("Distribution of Tree Votes by Class") +
facet_grid( lbool ~ .,margins=F) + xlab("Probability of Non-Efficacious") +
aes(y= ..density..) + ylab("Density of Individuals")
h.plot
?png
png("~/Dropbox/research/tnf/paper on methods/apply-to-unsure.png")
h.plot
dev.off()
cui.wide[1,1:2]
names(med.counts.wide)
summary(med.counts.wide)
summary(demo.wide)
load("~/Dropbox/research/phewas grs round 2/compiled_snp_details.RData")
load("~/Dropbox/research/phewas grs round 2/phewas.grs.by.site.exc.8nov14.random.adj.RData")
snps=meta.res.exc[!(meta.res.exc$snp %in% c("grs","wgrs","wgrs.nohla"))&meta.res.exc$adjustment=="NA",]
table(snps[snps$phenotype=="244",]$p<.05)
snps[snps$phenotype=="244"&snps$p<.05,]
hypo=snps[snps$phenotype=="244"&snps$p<.05,]
hypo=snps[snps$phenotype=="244"&snps$p<.05,1:7]
merge(hypo,details)
merge(hypo,details,by.x="snp",by.y="rsid")
?library
library(PheWAS)
vignette("PheWAS")
vignette(PheWAS)
?PheWAS
vignette("PheWAS-package")
install_github("PheWAS")
library(devtools)
install_github("PheWAS")
install_github("PheWAS/PheWAS")
?PheWAS
chisq.test(rbind(c(50,50),c(50,50)))
a=rbind(c(50,50),c(50,50))
a
chisq.test(a)
b=rbind(c(500,500),c(50,50))
chisq.test(b)
c=rbind(c(500,500),c(55,45))
chisq.test(c)
d=rbind(c(1500,500),c(150,50))
chisq.test(d)
d
e=rbind(c(1500,500),c(14,6))
chisq.test(3)
chisq.test(e)
e=rbind(c(1500,500),c(16,4))
chisq.test(e)
e=rbind(c(5000,500),c(16,4))
chisq.test(e)
e=rbind(c(5000,500),c(50,4))
chisq.test(e)
e=rbind(c(5000,500),c(50,6))
chisq.test(e)
?bibentry
setwd("C:/PheWAS")
install.packages("tidyr")
suppressWarnings(library(PheWAS))
set.seed(1)
ex=generateExample()
id.icd9.count=ex$id.icd9.count
head(phemap)
library(tidyr)
?join
head(id.icd9.count)
input=id.icd9.count
if(class(input$icd9) %in% c("integer","numeric")) {stop("Numeric ICD-9 codes passed in, so an accurate mapping is not possible. E.G.: 250, 250.0, and 250.00 are different codes and necessitate string representation")}
output = inner_join(input,phemap,by="icd9")
output = merge(input,phemap,by="icd9")
output = inner_join(input,phemap,by="icd9")
head(pheinfo)
head(output)
class(output)
?summarise
?group_by
phemapped=mapICD9toPheWAS(id.icd9.count)
source('C:/PheWAS/R/mapICD9toPheWAS.R')
phemapped=mapICD9toPheWAS(id.icd9.count)
phecode=data.frame(id=phemapped[,"id"],phe=phemapped[,"phewas_code"],count=phemapped[,"count"])
phemapped=mapICD9toPheWAS(id.icd9.count)
phemapped=data.frame(id=phemapped[,"id"],phe=phemapped[,"phewas_code"],count=phemapped[,"count"])
phecode=summarize(group_by(phemapped,id,phewas_code),count=aggregate.fun(count))
head(phemapped)
phecode=summarize(group_by(phemapped,id,phe),count=aggregate.fun(count))
aggregate.fun=sum
phecode=summarize(group_by(phemapped,id,phe),count=aggregate.fun(count))
head(phecode)
class(phecode$phe)
head(phecode,20)
class(phecode)
phens=spread(phecode,phe,count,fill=0)
?spread
?summarize
phecode=summarize(group_by(phemapped,id,phe),count=aggregate.fun(count))$data.frame
phens=spread(phecode,phe,count,fill=0)
phecode=summarize(group_by(phemapped,id,phe),count=aggregate.fun(count))
head(phecode)
phecode[1:10,1:3]
?group_by
phens=phecode %>% spread(phe,count,fill=0)
names(phecode)
a=head(phemapped)
spread(phemapped,phe,count)
spread(a,phe,count)
a
??summarize
?group_by
phecode=ungroup(summarize(group_by(phemapped,id,phe),count=aggregate.fun(count)))
head(phecode)
phens=spread(phecode,phe,count,fill=0)
phens[1:10,1:10]
phecode=ungroup(summarize(group_by(phemapped,id,phe),count=aggregate.fun(count)))
phecode=phecode[phecode$count>0,]
phecode[phecode$count<min.code.count,]$count=NA
min.code.count=2
phecode[phecode$count<min.code.count,]$count=NA
}
phecode[phecode$count<min.code.count,]$count=NA
phecode[!is.na(phecode$count)&phecode$count<min.code.count,]$count=NA
phecode=ungroup(summarize(group_by(phemapped,id,phe),count=aggregate.fun(count)))
phecode=phecode[phecode$count>0,]
phecode[!is.na(phecode$count)&phecode$count<min.code.count,]$count=NA
phecode=ungroup(summarize(group_by(phemapped,id,phe),count=aggregate.fun(count)))
phecode=phecode[phecode$count>0,]
#Check exclusions, and add them to the list
if(add.exclusions) {
message("Mapping exclusions...")
exclusions=mapPheWAStoExclusions(present_phecode$phe,present_phecode$id)
exclusions$count=NA
phecode=rbind(phecode,exclusions)
}
add.exclusions=T
if(add.exclusions) {
message("Mapping exclusions...")
exclusions=mapPheWAStoExclusions(present_phecode$phe,present_phecode$id)
exclusions$count=NA
phecode=rbind(phecode,exclusions)
}
exclusions=mapPheWAStoExclusions(phecode$phe,phecode$id)
source('C:/PheWAS/R/mapPheWAStoExclusions.R')
exclusions=mapPheWAStoExclusions(phecode$phe,phecode$id)
source('C:/PheWAS/R/mapPheWAStoExclusions.R')
exclusions=mapPheWAStoExclusions(phecode$phe,phecode$id)
exclusions$count=NA
phecode=rbind(phecode,exclusions)
head(exclusions)
head(phecode)
source('C:/PheWAS/R/mapPheWAStoExclusions.R')
exclusions=mapPheWAStoExclusions(phecode$phe,phecode$id)
exclusions$count=NA
phecode=rbind(phecode,exclusions)
summary(phecode)
#If there is request for a min code count, adjust counts to NA if needed
if(!is.na(min.code.count)) {
phecode[!is.na(phecode$count)&phecode$count<min.code.count,]$count=NA
}
?coalesce
??coalesce
?max
max(c(1,2),na.rm=T)
max(c(1,2,NA),na.rm=T)
max(c(NA),NA),na.rm=T)
max(c(NA,NA),na.rm=T)
max(c(1,2,NA))
phecode2=ungroup(summarize(group_by(phemapped,id,phe),count=function(count) {
no.na=na.omit(count)
ifelse(length(count)>0,max(count),NA)
}))
?ifelse
phecode2=ungroup(summarize(group_by(phemapped,id,phe),count=function(count) {
no.na=na.omit(count)
ifelse(length(count)>0,max(count),NA)
NA
}))
?summarize
coalesce=function(count) {
no.na=na.omit(count)
ifelse(length(count)>0,max(count),NA)
#NA
}
phecode2=ungroup(summarize(group_by(phemapped,id,phe),count=coalesce(count)))
phecode=ungroup(summarize(group_by(phemapped,id,phe),count=aggregate.fun(count)))
message("Aggregating PheWAS codes...")
phecode=ungroup(summarize(group_by(phemapped,id,phe),count=aggregate.fun(count)))
phecode=phecode[phecode$count>0,]
#Check exclusions, and add them to the list
if(add.exclusions) {
message("Mapping exclusions...")
exclusions=mapPheWAStoExclusions(phecode$phe,phecode$id)
exclusions$count=NA
phecode=rbind(phecode,exclusions)
}
#If there is request for a min code count, adjust counts to NA if needed
if(!is.na(min.code.count)) {
phecode[!is.na(phecode$count)&phecode$count<min.code.count,]$count=NA
}
message("Coalescing exclusions and min.code.count as applicable...")
coalesce=function(count) {
no.na=na.omit(count)
ifelse(length(count)>0,max(count),NA)
}
phecode=ungroup(summarize(group_by(phemapped,id,phe),count=coalesce(count)))
message("Reshaping data...")
phens=spread(phecode,phe,count,fill=0)
head(phecode)
if(!is.na(min.code.count)) { phecode$count=phecode$count>0}
head(phecode)
table(phecode$count)
table(phecode$count,useNA="ifany")
summary(phecode)
message("Aggregating PheWAS codes...")
phecode=ungroup(summarize(group_by(phemapped,id,phe),count=aggregate.fun(count)))
phecode=phecode[phecode$count>0,]
#Check exclusions, and add them to the list
if(add.exclusions) {
message("Mapping exclusions...")
exclusions=mapPheWAStoExclusions(phecode$phe,phecode$id)
exclusions$count=NA
phecode=rbind(phecode,exclusions)
}
#If there is request for a min code count, adjust counts to NA if needed
if(!is.na(min.code.count)) {
phecode[!is.na(phecode$count)&phecode$count<min.code.count,]$count=NA
}
message("Coalescing exclusions and min.code.count as applicable...")
coalesce=function(count) {
no.na=na.omit(count)
ifelse(length(count)>0,max(count),NA)
}
phecode=ungroup(summarize(group_by(phecode,id,phe),count=coalesce(count)))
#For min.code.count, turn into a binary outcome
if(!is.na(min.code.count)) { phecode$count=phecode$count>0}
message("Reshaping data...")
phens=spread(phecode,phe,count,fill=0)
head(phecode)
summary(phecode)
phens[1:10,1:10]
#For min.code.count, turn into a binary outcome
if(!is.na(min.code.count)) {
phecode$count=phecode$count>0
fill=TRUE
} else {
#Fill for no min.code.count
fill=0
}
phens=spread(phecode,phe,count,fill=fill)
phens[1:10,1:10]
fill=FALSE
phens=spread(phecode,phe,count,fill=fill)
phens[1:10,1:10]
source('C:/PheWAS/R/createPhewasTable.R')
phenotypes=createPhewasTable(id.icd9.count)
source('C:/PheWAS/R/createPhewasTable.R')
phenotypes=createPhewasTable(id.icd9.count)
